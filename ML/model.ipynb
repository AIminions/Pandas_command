{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# zip() 함수와 for문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[a, b ]] for a,b in zip(length, weight)] # 길이와 무게 데이터를 묶어서 data 리스트에 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 넘파이 배열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (769056852.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 10\u001b[1;36m\u001b[0m\n\u001b[1;33m    .reshape(-1, 1) # 1차원 배열을 2차원 배열로 변환\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = np.array(data) # data 리스트를 numpy 배열로 변환\n",
    "df.to_numpy() # 데이터프레임을 numpy 배열로 변환\n",
    "\n",
    "df = pd.DataFrame(data, columns=['length', 'weight']) # numpy 배열을 데이터프레임으로 변환\n",
    "df.to_csv('data.csv', index=False) # 데이터프레임을 csv 파일로 저장\n",
    "\n",
    ".reshape(-1, 1) # 1차원 배열을 2차원 배열로 변환\n",
    ".reshape(2, -1) # 1차원 배열을 2차원 배열로 변환    \n",
    "\n",
    ".arange(1, 10, 0.1) # 1부터 10까지 0.1 간격으로 배열 생성\n",
    ".linspace(1, 10, 100) # 1부터 10까지 100개의 구간으로 배열 생성\n",
    "\n",
    "np.clumns_stack(([1,2,3],[4,5,6])) # 두 배열을 열 방향으로 병합\n",
    "# ex) array([[1, 4],\n",
    "#            [2, 5],\n",
    "#            [3, 6]])\n",
    "np.row_stack(([1,2,3],[4,5,6])) # 두 배열을 행 방향으로 병합\n",
    "# ex) array([[1, 2, 3],\n",
    "#            [4, 5, 6]])\n",
    "\n",
    "np.random.rand(2, 3) # 2x3 크기의 난수 배열 생성\n",
    "np.random.randint(1, 100, 10) # 1부터 100까지 10개의 정수 난수 생성\n",
    "\n",
    "np.ones((2, 3)) # 2x3 크기의 1로 채워진 배열 생성\n",
    "np.zeros((2, 3)) # 2x3 크기의 0으로 채워진 배열 생성    \n",
    "\n",
    "np.concatenate(([[1,2,3], [4,5,6]]), axis=0) # 두 배열을 행 방향으로 연결\n",
    "# ex) array([[1, 2, 3],\n",
    "#            [4, 5, 6]])\n",
    "\n",
    "print(np.concatenate([[1, 2, 3], [4, 5, 6]])) # 두 배열을 열 방향으로 연결\n",
    "# ex) array([1, 2, 3, 4, 5, 6])\n",
    "\n",
    "np.delete(arr, 1, axis=0) # 1번 행 삭제\n",
    "np.delete(arr, 1, axis=1) # 1번 열 삭제\n",
    "\n",
    "pd.unique(df['column']) # 중복을 제거한 값만 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# poly ( polynomial 다항식 ) 과소적합일때 씀."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skleran.preprocessing import PolynomialFeatures \n",
    "\n",
    "poly = PolynomialFeatures(include_bias=False) # 다항 특성 객체 생성\n",
    "\n",
    "poly.fit_transform([[2,3]]) # 다항 특성으로 변환\n",
    "# ex) array([[1., 2., 3., 4., 6., 9.]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 그래프 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(data[:, 0], data[:, 1], c=target) # 산점도 그리기\n",
    "plt.scatter(20, 150, marker='^', c='red') # 새로운 데이터 그리기\n",
    "plt.xlabel('length')\n",
    "plt.ylabel('weight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 테스트 세트와 훈련세트 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train input , train target , test input , test target = train_test_split(train, target, test_size=0.2, random_state=42)\n",
    "# 데이터를 훈련 세트와 테스트 세트로 나눔 ( 8:2 비율로 나눔 ) random_state는 난수 초깃값을 지정 \n",
    "# random_state를 지정하면 여러 번 실행해도 같은 결과를 얻을 수 있음\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 최근접 이웃 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# K-최근접 이웃 모델을 생성\n",
    "# 그래프에 가장 가까운 이웃을 찾아서 분류하는 알고리즘\n",
    "\n",
    "\n",
    "\n",
    "kn = KNeighborsClassifier(n_neighbors=1) # 이웃의 개수를 1로 지정 ( 기본 5 )\n",
    "kn.n_neighbors = x # 이웃의 개수를 변경하고 싶을 때\n",
    "\n",
    "kn.fit(data, target) # 모델 훈련\n",
    "kn.predict([[20, 150]]) # 새로운 데이터에 대해 예측 항상 2차원 배열로 전달\n",
    "kn.score(data, target) # 모델의 정확도 계산 \n",
    "# 1.0 -> 100% 정확도\n",
    "# 정확도 = (정확히 예측한 개수) / (전체 데이터 개수)\n",
    "\n",
    "distance , indexes = kn.kneighbors([[x, y]]) # 가장 가까운 이웃까지의 거리와 인덱스를 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 최근접 이웃 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from.sklearn.linear_model import LinearRegression\n",
    "from.sklearn.metrics import mean_squared_error , r2_score # 평균 제곱 오차와 R^2 점수를 계산\n",
    "from.sklearn.metrics import mean_absolute_error # 평균 절대 오차를 계산\n",
    "\n",
    "test_prediction = model.predict(test_input) # 테스트 데이터에 대한 예측\n",
    "\n",
    "mse = mean_squared_error(test_target, test_prediction) # 평균 제곱 오차 계산\n",
    "mae = mean_absolute_error(test_target, test_prediction) # 평균 절대 오차 계산\n",
    "r2 = r2_score(test_target, test_prediction) # R^2 점수 계산\n",
    "print(mse, mae, r2)\n",
    "\n",
    "R^2 = 1 - (오차 제곱의 합 / 편차 제곱의 합)\n",
    "# R^2 값이 1에 가까울수록 모델이 데이터를 잘 표현한다는 의미\n",
    "# R^2 값이 0에 가까울수록 모델이 데이터를 잘 표현하지 못한다는 의미\n",
    "# R^2 값이 음수가 나오면 모델이 데이터를 현저히 잘못 표현했다는 의미\n",
    "\n",
    "lr = LinearRegression() # 선형 회귀 모델 생성\n",
    "lr.fit(train_input, train_target) # 모델 훈련\n",
    "\n",
    "print(lr.predict([[50]])) # 새로운 데이터에 대한 예측 > [1241.83860323]\n",
    "# 선형 회귀 모델의 기울기와 절편은 coef_와 intercept_ 속성에 저장\n",
    "print(lr.coef_, lr.intercept_) # 모델 파라미터 출력\n",
    "# ex) [39.01714496] -709.0186449535477\n",
    "\n",
    "plt.scatter(train_input, train_target) # 훈련 데이터의 산점도 그리기\n",
    "plt.plot([15, 50], [15*lr.coef_+lr.intercept_, 50*lr.coef_+lr.intercept_]) # 15에서 50까지 예측 그래프 그리기\n",
    "\n",
    "# 새로운 데이터의 산점도 그리기\n",
    "plt.scatter(50, 1241.8, marker='^') # 새로운 데이터의 산점도 그리기\n",
    "plt.xlabel('length') # x축 레이블 설정\n",
    "plt.ylabel('weight') # y축 레이블 설정\n",
    "plt.show() # 그래프 출력\n",
    "\n",
    "print(lr.score(train_input, train_target)) # 훈련 데이터에 대한 R^2 점수 출력\n",
    "print(lr.score(test_input, test_target)) # 테스트 데이터에 대한 R^2 점수 출력\n",
    "# 과대적합인지 과소적합인지 확인.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 규제 ( regulation , 과대적합 방지 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge # 릿지 회귀  , 제곱규제를 사용\n",
    "ridge = Ridge(alpha=0.1) # 릿지 회귀 객체 생성 알파값은 얼마나 규제를 할지 결정 값이 클수록 규제가 강해짐 기본값 1.0\n",
    "ridge.fit(X_train, y_train) # 릿지 회귀 모델 훈련\n",
    "print(ridge.score(X_test, y_test)) # 릿지 회귀 모델 평가\n",
    "\n",
    "from sklearn.linear_model import Lasso # 라쏘 회귀  , 절댓값 규제를 사용 계수를 0으로 만들 수 있음\n",
    "lasso = Lasso(alpha=0.1) # 라쏘 회귀 객체 생성\n",
    "lasso.fit(X_train, y_train) # 라쏘 회귀 모델 훈련\n",
    "print(lasso.score(X_test, y_test)) # 라쏘 회귀 모델 평가\n",
    "\n",
    "# 라쏘의 계수는 coef_ 속성에 저장\n",
    "print(np.sum(lasso.coef_  == 0 )) # 0인 계수의 개수 출력해서 중요하지 않은 특성을 찾을 수 있음 ex) 2 = 2개의 특성이 중요하지 않음\n",
    "\n",
    "from sklearn.linear_model import ElasticNet # 엘라스틱넷 회귀 , 릿지와 라쏘를 절충한 모델\n",
    "elastic_net = ElasticNet(alpha=0.1, l1_ratio=0.5) # 엘라스틱넷 회귀, 객체 생성 알파값은 규제의 강도를 결정 l1_ratio는 라쏘 규제의 비율을 결정\n",
    "elastic_net.fit(X_train, y_train) # 엘라스틱넷 회귀 모델 훈련\n",
    "print(elastic_net.score(X_test, y_test)) # 엘라스틱넷 회귀 모델 평가\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression # 로지스틱 회귀 \n",
    "logistic = LogisticRegression() # 로지스틱 회귀 객체 생성\n",
    "logistic.fit(X_train, y_train) # 로지스틱 회귀 모델 훈련\n",
    "print(logistic.score(X_test, y_test)) # 로지스틱 회귀 모델 평가\n",
    "\n",
    "data_input = data[['length', 'weight', 'diagonal', 'height']].to_numpy() # 열 선택 후 numpy 배열로 변환\n",
    "data_target = data['species'].to_numpy() # 열 선택 후 numpy 배열로 변환\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC # 서포트 벡터 머신 모델 클래스\n",
    "svc = SVC() # 서포트 벡터 머신 객체 생성\n",
    "svc.fit(X_train, y_train) # 서포트 벡터 머신 모델 훈련\n",
    "print(svc.score(X_test, y_test)) # 서포트 벡터 머신 모델 평가\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier # 결정 트리 모델 클래스\n",
    "decision_tree = DecisionTreeClassifier() # 결정 트리 객체 생성\n",
    "decision_tree.fit(X_train, y_train) # 결정 트리 모델 훈련\n",
    "print(decision_tree.score(X_test, y_test)) # 결정 트리 모델 평가\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier # 랜덤 포레스트 모델 클래스\n",
    "random_forest = RandomForestClassifier() # 랜덤 포레스트 객체 생성\n",
    "random_forest.fit(X_train, y_train) # 랜덤 포레스트 모델 훈련\n",
    "print(random_forest.score(X_test, y_test)) # 랜덤 포레스트 모델 평가\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier # 그래디언트 부스팅 모델 클래스\n",
    "gradient_boost = GradientBoostingClassifier() # 그래디언트 부스팅 객체 생성\n",
    "gradient_boost.fit(X_train, y_train) # 그래디언트 부스팅 모델 훈련\n",
    "print(gradient_boost.score(X_test, y_test)) # 그래디언트 부스팅 모델 평가\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier # 다층 퍼셉트론 모델 클래스\n",
    "mlp = MLPClassifier() # 다층 퍼셉트론 객체 생성\n",
    "mlp.fit(X_train, y_train) # 다층 퍼셉트론 모델 훈련\n",
    "print(mlp.score(X_test, y_test)) # 다층 퍼셉트론 모델 평가\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 스케일링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler # 표준화 클래스\n",
    "scaler = StandardScaler() # 표준화 객체 생성\n",
    "scaler.fit_transform(X_train) # 훈련 데이터 표준화\n",
    "scaler.transform(X_test) # 테스트 데이터 표준화\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 알파 값을 늘리며 최적값 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "train_score = []\n",
    "test_score = []\n",
    "\n",
    "alpah_list = [0.001, 0.01, 0.1, 1, 10, 100] # 알파값 리스트\n",
    "for alpha in alpha_list:\n",
    "    ridge = Ridge(alpha=alpha) # 릿지 회귀 모델 생성\n",
    "    ridge.fit(X_train, y_train) # 릿지 회귀 모델 훈련\n",
    "    train_score.append(ridge.score(X_train, y_train)) # 훈련 점수 저장\n",
    "    test_score.append(ridge.score(X_test, y_test)) # 테스트 점수 저장\n",
    "\n",
    "plt.plot(np.log10(alpha_list), train_score) # 훈련 점수 그래프 그리기 로그로 표현해서 보기 편하게 함. ex ) 0.001 -> -3 = 10^-3\n",
    "plt.plot(np.log10(alpha_list), test_score) # 테스트 점수 그래프 그리기\n",
    "plt.xlabel('alpha') # x축 레이블 설정\n",
    "plt.ylabel('R^2') # y축 레이블 설정 ( 스코어 )\n",
    "plt.show() # 그래프 출력\n",
    "\n",
    "# 훈련 점수와 테스트 점수가 가장 가까운 지점이 최적의 알파값"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
